import pandas as pd
import os
import numpy as np
import joblib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from xgboost import XGBClassifier, plot_importance
import json
from sklearn.metrics import f1_score, recall_score, precision_score

class XGBoostModelTrainer:
    def __init__(self, seed=42, device='cuda'):
        self.seed = seed
        self.device = device
        self.model = None
        self.best_params = None

    def train(self, dataset_path: str, output_folder: str, parameters=None, test_on_original=False):
        # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)

        # è®¾ç½®éšæœºç§å­
        np.random.seed(self.seed)

        # åŠ è½½æ•°æ®
        df = pd.read_pickle(dataset_path)
        print(f"Dataset shape: {df.shape}")

        # è¯†åˆ«ç›®æ ‡åˆ—
        if 'MAL' in dataset_path:
            target_col = "Malnutrition"
        elif 'CAP' in dataset_path:
            target_col = "CAP_Nutrition"
        else:
            print("Unknown dataset format. Please provide a valid dataset start with CAP or MAL.")
            return None

        # --- æ ¹æ® test_on_original å†³å®šåˆ‡åˆ†ç­–ç•¥ ---
        if test_on_original:
            if 'IDno' not in df.columns:
                raise ValueError("IDno åˆ—ä¸å­˜åœ¨ï¼Œæ— æ³•ä»…åœ¨åŸå§‹æ•°æ®ä¸Šæµ‹è¯•ã€‚è¯·ç¡®ä¿å¢å¼ºå‰ä¿ç•™ IDnoã€‚")
            orig_mask = df['IDno'].notna()
            df_orig = df.loc[orig_mask]
            if df_orig.empty:
                raise ValueError("åŸå§‹æ•°æ®å­é›†ä¸ºç©ºï¼ˆIDno å…¨ä¸º NaNï¼‰ã€‚")

            stratify_y = df_orig[target_col] if df_orig[target_col].nunique() > 1 else None
            train_idx_orig, test_idx = train_test_split(
                df_orig.index,
                test_size=0.2,
                random_state=self.seed,
                stratify=stratify_y
            )
            train_df = df.drop(index=test_idx)   # è®­ç»ƒé›†=æ•´ä»½æ•°æ®å‰”é™¤åŸå§‹æµ‹è¯•ç´¢å¼•ï¼ˆå«åŸå§‹è®­ç»ƒ+å…¨éƒ¨å¢å¼ºï¼‰
            test_df = df.loc[test_idx]           # æµ‹è¯•é›†=ä»…åŸå§‹æ ·æœ¬
            print(f"[Split] test_on_original=True -> Test only from original samples (IDno notna).")
        else:
            stratify_y = df[target_col] if df[target_col].nunique() > 1 else None
            train_idx, test_idx = train_test_split(
                df.index,
                test_size=0.2,
                random_state=self.seed,
                stratify=stratify_y
            )
            train_df = df.loc[train_idx]
            test_df  = df.loc[test_idx]
            print(f"[Split] test_on_original=False -> Standard random split on full dataset.")

        # ä¸¢å¼ƒæ— å…³åˆ—åæ„å»º X/y
        drop_cols = [c for c in ['IDno', 'Assessment_Date'] if c in df.columns]
        X_train = train_df.drop(columns=drop_cols + [target_col])
        y_train = train_df[target_col]
        X_test  = test_df.drop(columns=drop_cols + [target_col])
        y_test  = test_df[target_col]

        print(f"Training set size: {X_train.shape[0]}  "
            f"({'åŒ…å«å¢å¼ºæ ·æœ¬' if test_on_original else 'å¯èƒ½åŒ…å«å¢å¼ºæ ·æœ¬'})")
        print(f"Test set size: {X_test.shape[0]}      "
            f"({'ä»…åŸå§‹æ ·æœ¬' if test_on_original else 'åŸå§‹+å¢å¼ºæ··åˆ'})")


        # å‚æ•°æœç´¢ç©ºé—´ï¼ˆå¯æ›¿æ¢ä¸ºæ›´å¤§ç©ºé—´ï¼‰
        params = {
            'max_depth': [5, 7, 10],
            'learning_rate': [0.01, 0.1],
            'n_estimators': [50, 100, 200],
            'subsample': [0.6, 0.8, 1],
            'colsample_bytree': [0.6, 0.8, 1],
        }

        if parameters:
            params = parameters

        # å®šä¹‰æ¨¡å‹
        xgb = XGBClassifier(
            eval_metric='mlogloss',
            tree_method='hist',
            device=self.device,
            random_state=self.seed
        )

        # ç½‘æ ¼æœç´¢
        grid = GridSearchCV(xgb, params, cv=5, verbose=1, n_jobs=1)
        grid.fit(X_train, y_train)

        print("Best parameters found:", grid.best_params_)
        self.model = grid.best_estimator_
        self.best_params = grid.best_params_

        # æµ‹è¯•é›†é¢„æµ‹ä¸è¯„ä¼°
        y_test_pred = self.model.predict(X_test)
        print("Test Results:")
        print("Accuracy:", accuracy_score(y_test, y_test_pred))
        print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
        print("Classification Report:\n", classification_report(y_test, y_test_pred))

        

        # è®¡ç®—å¤šåˆ†ç±»æŒ‡æ ‡ï¼ˆmacro æ˜¯å¯¹æ¯ç±»åˆ†åˆ«è®¡ç®—å†å¹³å‡ï¼Œä¸å—ç±»åˆ«ä¸å¹³è¡¡å½±å“ï¼‰
        accuracy = accuracy_score(y_test, y_test_pred)
        f1_macro = f1_score(y_test, y_test_pred, average='macro')
        recall_macro = recall_score(y_test, y_test_pred, average='macro')  # Sensitivity
        precision_macro = precision_score(y_test, y_test_pred, average='macro')

        print("\nğŸ” Multi-class Evaluation Metrics (macro average):")
        print(f"Accuracy       : {accuracy:.4f}")
        print(f"Sensitivity    : {recall_macro:.4f}")      # i.e. macro recall
        print(f"F1-score       : {f1_macro:.4f}")
        print(f"Precision      : {precision_macro:.4f}")


        # å­æ–‡ä»¶å¤¹å‘½å
        dataset_name = os.path.basename(dataset_path).split('.')[0]
        target_subfolder = os.path.join(output_folder, 'xgb_' + dataset_name)
        if not os.path.exists(target_subfolder):
            os.makedirs(target_subfolder)

        # ä¿å­˜æ¨¡å‹
        model_path = os.path.join(target_subfolder, f'{dataset_name}_xgb_model.pkl')
        joblib.dump(self.model, model_path)
        print(f"Model saved to {model_path}")

        # ä¿å­˜æœ€ä½³å‚æ•°
        self.save_best_params(target_subfolder, dataset_name)

        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§å›¾
        importances = self.model.feature_importances_

        # å°†é‡è¦æ€§å½’ä¸€åŒ–ä¸ºç™¾åˆ†æ¯”ï¼ˆæ€»å’Œä¸º100ï¼‰
        importances_pct = importances / importances.sum() * 100

        # è·å– top 12 ç‰¹å¾çš„ç´¢å¼•å’Œæ•°å€¼
        indices = np.argsort(importances_pct)[::-1]
        top_n = 10
        top_indices = indices[:top_n]
        top_features = X_train.columns[top_indices]
        top_importances = importances_pct[top_indices]
        # Print the top 12 features in one line
        # top_features_str = ', '.join([f"{feat} ({imp:.2f}%)" for feat, imp in zip(top_features, top_importances)])
        top_features_str = ', '.join([f"{feat}" for feat, imp in zip(top_features, top_importances)])
        print(f"Top 12 features: {top_features_str}")

        # ç”»å›¾
        plt.figure(figsize=(10, 6))
        bars = plt.barh(range(top_n), top_importances[::-1], align='center')
        plt.yticks(range(top_n), top_features[::-1])
        plt.xlabel("Feature Importance (%)")
        plt.title("Top " + str(top_n) + " Most Important Features (xgb_" + dataset_name + ")")
        plt.tight_layout()

        # åœ¨æ¯ä¸ªæ¡å½¢å›¾æ—è¾¹åŠ ä¸Šç™½è‰²æ•°å€¼æ ‡ç­¾
        for i, (value, bar) in enumerate(zip(top_importances[::-1], bars)):
            plt.text(0.1, bar.get_y() + bar.get_height() / 2,
                    f'{value:.2f}%', va='center', color='white')

        # ä¿å­˜å›¾åƒ
        plot_path = os.path.join(target_subfolder, f'{dataset_name}_xgb_importance.png')
        plt.savefig(plot_path, dpi=300)
        plt.close()

        print(f"Top 12 feature importance plot saved to {plot_path}")

        # Print the top 12 features in one line
        # top_features_str = ', '.join([f"{feat} ({imp:.2f}%)" for feat, imp in zip(top_features, top_importances)])
        top_features_str = ', '.join([f"{feat}" for feat, imp in zip(top_features, top_importances)])
        print(f"Top 12 features: {top_features_str}")


        # # å¯é€‰ï¼šç”¨ XGBoost å†…ç½®ç”»æ³•å†ç”»ä¸€å¼ 
        # plt.figure(figsize=(12, 8))
        # plot_importance(self.model, max_num_features=12, importance_type='gain')
        # plt.tight_layout()
        # builtin_plot_path = os.path.join(target_subfolder, f'{dataset_name}_xgb_builtin_importance.png')
        # plt.savefig(builtin_plot_path, dpi=300)
        # plt.close()
        # print(f"XGBoost built-in feature importance plot saved to {builtin_plot_path}")

        return self.model

    def save_best_params(self, output_folder, dataset_name):
        if self.best_params is not None:
            params_path = os.path.join(output_folder, f'{dataset_name}_xgb_best_params.json')
            with open(params_path, 'w') as f:
                json.dump(self.best_params, f, indent=4)
            print(f"Best parameters saved to {params_path}")
        else:
            print("No best parameters to save.")