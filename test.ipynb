{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msoffcrypto\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import locale\n",
    "from utils import calculate_age, drop_columns, average_fill_empty, calculate_malnutrition, drop_cap_nutrition_rows, generate_gender_column_and_carelevel, check_missing_values, fill_missing_by_idno_and_mode\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Reading an encrypted Excel file\n",
    "encrypted_file_path = \"./datasets/InterRAI Pt 4 2505.xlsx\"\n",
    "target_folder = \"./datasets/\"\n",
    "# Use password in .env\n",
    "load_dotenv()\n",
    "# Reading an encrypted Excel file\n",
    "# encrypted_file_path = os.getenv(\"CSV_PATH\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "\n",
    "\n",
    "with open(encrypted_file_path, \"rb\") as f:\n",
    "    office_file = msoffcrypto.OfficeFile(f)\n",
    "    office_file.load_key(password=password)\n",
    "    # Decrypt the file\n",
    "    decrypted = io.BytesIO()\n",
    "    office_file.decrypt(decrypted)\n",
    "\n",
    "    dfs = pd.read_excel(decrypted, sheet_name=None, engine=\"openpyxl\")\n",
    "basic_info_df = dfs[\"Staying Upright InterRAI\"]\n",
    "extra_info_df = dfs[\"Staying Upright demo2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    IDno        Age\n",
      "0  01001  87.166667\n",
      "1  01001  87.750000\n",
      "2  01001  87.916667\n",
      "3  01001  88.083333\n",
      "4  01001  88.416667\n",
      "5  01001  88.916667\n",
      "6  01001  89.416667\n",
      "7  01002  84.250000\n",
      "8  01002  84.666667\n",
      "9  01002  85.166667\n",
      "   CareLevel  Gender\n",
      "0        1.0     2.0\n",
      "1        3.0     2.0\n",
      "2        3.0     1.0\n",
      "3        3.0     1.0\n",
      "4        3.0     1.0\n",
      "5        1.0     2.0\n",
      "6        3.0     1.0\n",
      "7        1.0     2.0\n",
      "8        1.0     2.0\n",
      "9        3.0     2.0\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the DataFrames\n",
    "df = calculate_age(basic_info_df, extra_info_df)\n",
    "df = generate_gender_column_and_carelevel(basic_info_df, extra_info_df)\n",
    "# # Check for missing values\n",
    "# columns_to_check = ['iJ1g', 'iJ1h', 'iJ1i', 'iJ12', 'iK1ab', 'iK1bb']\n",
    "# check_missing_values(columns_to_check, df)\n",
    "df = drop_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cap df\n",
    "cap_df = drop_cap_nutrition_rows(df)\n",
    "cap_df = fill_missing_by_idno_and_mode(cap_df)\n",
    "cap_df = calculate_malnutrition(cap_df)\n",
    "cap_df.to_pickle(target_folder + 'cap_data.pkl')\n",
    "# df = pd.read_pickle(target_folder + 'cap_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mal df\n",
    "mal_df = fill_missing_by_idno_and_mode(df)\n",
    "mal_df = calculate_malnutrition(df)\n",
    "mal_df = mal_df.drop(columns=[\"iK2a\", \"iK2g\", \"iG3\", \"iE2a\", \"iE2b\", \"iE2c\", \"iI1c\", \"iI1d\", \"CAP_Nutrition\"])\n",
    "mal_df.to_pickle(target_folder + 'mal_data.pkl')\n",
    "# mal_df = pd.read_pickle(target_folder + 'mal_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a25094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cap = pickle.load(open('./datasets/cap_data.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68ea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "       IDno Assessment_Date  A8  CAP_ADL  CAP_Activities  CAP_Behaviour  \\\n",
      "0     01001       23JAN2017   2        0               0              0   \n",
      "1     01001       29AUG2017   2        0               0              0   \n",
      "2     01001       24OCT2017   4        0               1              0   \n",
      "3     01001       28DEC2017   4        2               1              0   \n",
      "4     01001       16APR2018   2        1               1              0   \n",
      "...     ...             ...  ..      ...             ...            ...   \n",
      "3453  26026       14AUG2020   2        1               0              0   \n",
      "3454  26026       10FEB2021   2        0               0              0   \n",
      "3455  26026       15FEB2021   2        0               0              0   \n",
      "3456  26026       14AUG2021   2        0               0              0   \n",
      "3457  26026       06FEB2022   2        0               0              0   \n",
      "\n",
      "      CAP_Bowel  CAP_Cardio  CAP_Cognitive  CAP_Communication  ...  iS2o  \\\n",
      "0             0           1              0                  2  ...     4   \n",
      "1             0           1              0                  2  ...     4   \n",
      "2             0           1              0                  2  ...     4   \n",
      "3             2           1              0                  2  ...     4   \n",
      "4             2           1              0                  2  ...     4   \n",
      "...         ...         ...            ...                ...  ...   ...   \n",
      "3453          0           0              0                  1  ...     4   \n",
      "3454          0           0              0                  1  ...     4   \n",
      "3455          0           0              0                  1  ...     4   \n",
      "3456          0           0              0                  1  ...     4   \n",
      "3457          0           0              0                  0  ...     4   \n",
      "\n",
      "      iS2r  iS3  iJ2y  iR7  iJ1g  iJ1h  iJ1i  iJ12  Malnutrition  \n",
      "0        4    0     0    5     0     0     0     0             0  \n",
      "1        4    0     0    5     0     0     0     0             0  \n",
      "2        3    0     0    5     1     0     0     0             0  \n",
      "3        4    1     0    5     2     2     2     1             1  \n",
      "4        4    1     0    5     1     1     1     0             0  \n",
      "...    ...  ...   ...  ...   ...   ...   ...   ...           ...  \n",
      "3453     4    0     0    5     0     0     0     0             0  \n",
      "3454     4    0     0    5     0     0     0     0             0  \n",
      "3455     4    0     0    5     0     0     0     0             0  \n",
      "3456     4    0     0    5     0     0     0     0             0  \n",
      "3457     4    0     0    5     0     0     0     0             0  \n",
      "\n",
      "[3458 rows x 269 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 打开并加载 mal_data.pkl\n",
    "target_folder = \"./datasets/\"\n",
    "with open(target_folder + \"mal_data.pkl\", \"rb\") as f:\n",
    "    mal = pickle.load(f)\n",
    "\n",
    "# 查看数据类型\n",
    "print(type(data))\n",
    "# 根据内容进一步查看\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c898e9",
   "metadata": {},
   "source": [
    "TESTING GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59095e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA version: 12.1\n",
      "CUDA available: True\n",
      "✅ 当前 GPU 设备： NVIDIA GeForce RTX 5070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\envs\\p4p\\Lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Laptop GPU with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ 模型没有在 GPU 上运行，可能有兼容性问题。\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[43mtest_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mtest_gpu\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     27\u001b[39m         out = \u001b[38;5;28mself\u001b[39m.fc(ht[-\u001b[32m1\u001b[39m])\n\u001b[32m     28\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model = \u001b[43mSimpleLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# 生成模拟数据\u001b[39;00m\n\u001b[32m     33\u001b[39m batch_size = \u001b[32m16\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\anaconda\\envs\\p4p\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1337\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1338\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1340\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\anaconda\\envs\\p4p\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    904\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    911\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\anaconda\\envs\\p4p\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:288\u001b[39m, in \u001b[36mRNNBase._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    283\u001b[39m ret = \u001b[38;5;28msuper\u001b[39m()._apply(fn, recurse)\n\u001b[32m    285\u001b[39m \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_flat_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\anaconda\\envs\\p4p\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:215\u001b[39m, in \u001b[36mRNNBase._init_flat_weights\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28mself\u001b[39m._flat_weights = [\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._flat_weights_names\n\u001b[32m    211\u001b[39m ]\n\u001b[32m    212\u001b[39m \u001b[38;5;28mself\u001b[39m._flat_weight_refs = [\n\u001b[32m    213\u001b[39m     weakref.ref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._flat_weights\n\u001b[32m    214\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflatten_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\anaconda\\envs\\p4p\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:269\u001b[39m, in \u001b[36mRNNBase.flatten_parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proj_size > \u001b[32m0\u001b[39m:\n\u001b[32m    268\u001b[39m     num_weights += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cudnn_rnn_flatten_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_cudnn_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproj_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "def test_gpu():\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"❌ GPU 不可用，模型将只能使用 CPU。\")\n",
    "        return\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"✅ 当前 GPU 设备：\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # 构造一个简单的 LSTM 模型\n",
    "    class SimpleLSTM(nn.Module):\n",
    "        def __init__(self, input_size=32, hidden_size=64):\n",
    "            super(SimpleLSTM, self).__init__()\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "            self.fc = nn.Linear(hidden_size, 3)\n",
    "\n",
    "        def forward(self, x, lengths):\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_out, (ht, ct) = self.lstm(packed)\n",
    "            out = self.fc(ht[-1])\n",
    "            return out\n",
    "\n",
    "    model = SimpleLSTM().to(device)\n",
    "\n",
    "    # 生成模拟数据\n",
    "    batch_size = 16\n",
    "    seq_len = 10\n",
    "    input_size = 32\n",
    "    dummy_input = torch.randn(batch_size, seq_len, input_size).to(device)\n",
    "    dummy_lengths = torch.tensor([seq_len]*batch_size).to(device)\n",
    "\n",
    "    # 前向传播并计时\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input, dummy_lengths)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"✅ 模型输出 device:\", output.device)\n",
    "    print(\"✅ 推理耗时: {:.6f} 秒\".format(end_time - start_time))\n",
    "\n",
    "    if str(output.device).startswith(\"cuda\"):\n",
    "        print(\"🎉 恭喜！模型已在 GPU 上成功运行。\")\n",
    "    else:\n",
    "        print(\"⚠️ 模型没有在 GPU 上运行，可能有兼容性问题。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_gpu()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
